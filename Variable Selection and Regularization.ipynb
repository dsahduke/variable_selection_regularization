{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Setpu\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "diabetes_df = pd.read_csv(\"../data/diabetes_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "readmitted_outcome = [0 if x == 'NO' else 1 for x in diabetes_df['readmitted']]\n",
    "first_number_regex = re.compile(r'^\\[(\\d*)') # Matches a bracket followed by numbers (0 or more, greedy)\n",
    "\n",
    "def extract_minimum_age(age):\n",
    "    matching_number = first_number_regex.match(age).group(1) # first matching group only extract the number\n",
    "    return int(matching_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df['age'].apply(extract_minimum_age)\n",
    "model_subset = diabetes_df.loc[:, ['encounter_id', 'race', 'gender', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses', 'time_in_hospital']].copy()\n",
    "id_subset = diabetes_df.loc[:, ['encounter_id', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id']].copy()\n",
    "ccs_subset = diabetes_df.loc[:, ['encounter_id', 'CCS Category Description 1', 'CCS Category Description 2', 'CCS Category Description 3']].copy()\n",
    "model_subset = pd.get_dummies(model_subset, prefix = \"ind_\", dummy_na = True, drop_first = True)\n",
    "id_subset = pd.get_dummies(id_subset, columns = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id'],prefix = {x:x for x in id_subset.columns if x is not 'encounter_id'}, dummy_na = True, drop_first = True)\n",
    "ccs_subset = pd.get_dummies(ccs_subset, prefix = \"ind_\", dummy_na = True, drop_first = True)\n",
    "ccs_subset = ccs_subset.groupby(ccs_subset.columns, axis = 1).sum()\n",
    "model_dataset = (model_subset.merge(id_subset, how = \"left\", on = \"encounter_id\")\n",
    "                             .merge(ccs_subset, how = \"left\", on = \"encounter_id\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>ind__Asian</th>\n",
       "      <th>...</th>\n",
       "      <th>ind__Ulcerat col</th>\n",
       "      <th>ind__Unclassified</th>\n",
       "      <th>ind__Urin stone</th>\n",
       "      <th>ind__Uterus cancr</th>\n",
       "      <th>ind__Varicose vn</th>\n",
       "      <th>ind__Viral infect</th>\n",
       "      <th>ind__Wht blood dx</th>\n",
       "      <th>ind__chf;nonhp</th>\n",
       "      <th>ind__gu cong anom</th>\n",
       "      <th>ind__nan_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2278392</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>149190</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>64410</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>500364</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>16680</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0       2278392                  41               0                1   \n",
       "1        149190                  59               0               18   \n",
       "2         64410                  11               5               13   \n",
       "3        500364                  44               1               16   \n",
       "4         16680                  51               0                8   \n",
       "\n",
       "   number_outpatient  number_emergency  number_inpatient  number_diagnoses  \\\n",
       "0                  0                 0                 0                 1   \n",
       "1                  0                 0                 0                 9   \n",
       "2                  2                 0                 1                 6   \n",
       "3                  0                 0                 0                 7   \n",
       "4                  0                 0                 0                 5   \n",
       "\n",
       "   time_in_hospital  ind__Asian  ...  ind__Ulcerat col  ind__Unclassified  \\\n",
       "0                 1           0  ...                 0                  0   \n",
       "1                 3           0  ...                 0                  0   \n",
       "2                 2           0  ...                 0                  0   \n",
       "3                 2           0  ...                 0                  0   \n",
       "4                 1           0  ...                 0                  0   \n",
       "\n",
       "   ind__Urin stone  ind__Uterus cancr  ind__Varicose vn  ind__Viral infect  \\\n",
       "0                0                  0                 0                  0   \n",
       "1                0                  0                 0                  0   \n",
       "2                0                  0                 0                  0   \n",
       "3                0                  0                 0                  0   \n",
       "4                0                  0                 0                  0   \n",
       "\n",
       "   ind__Wht blood dx  ind__chf;nonhp  ind__gu cong anom  ind__nan_y  \n",
       "0                  0               0                  0           2  \n",
       "1                  0               0                  0           0  \n",
       "2                  0               0                  0           2  \n",
       "3                  0               0                  0           0  \n",
       "4                  0               0                  0           1  \n",
       "\n",
       "[5 rows x 266 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 266)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So far, all of the methods that we have described assume that we have some data, $\\textbf{X}$. Our goal has been to learn a mapping from the data, $\\textbf{X}$, to some labels $\\textbf{y}$. However, what if some elements of $\\textbf{X}$ are not useful in this mapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ## Variable Selection\n",
    "Given some predictors $x_1, x_2, \\dots$, how do we select the subset that are most useful in our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For this example, let's say we have $p$ predictors. That is, our predictors are $x_j, j = 1 \\dots p$. How do we determine which indices $j$ should belong in a final model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Best Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The naive way to do this is to just fit every single possible model and then select the best one according to some criterion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, we would fit every model:\n",
    "\n",
    "$$ y = \\beta_0 $$\n",
    "$$ y = \\beta_0 + \\beta_1x_1 $$\n",
    "$$ y = \\beta_0 + \\beta_1x_2 $$ \n",
    "$$ y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This will result in $2^p$ models, which is ... a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Practically, this subset selection is done in stages, that is:\n",
    "\n",
    " 1. for $ j = 1 \\dots p $:\n",
    "     - Fit all ${p \\choose j}$ possible models that have $j$ predictors\n",
    "     - Pick the best model among those according to the smallest RSS or largest $R^2$\n",
    " 2. for $ j = 1 \\dots p $ and the null model, $y = \\beta_0$, select the model among the \"best\" models according to some criterion ($C_p$, BIC, adjusted $R^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The problem with this method is obvious -- with $p$ = 20, there are over 1 million possible models to consider. Consider the problem of multiple comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How do we narrow down the number of models to consider?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stepwise Selection\n",
    "\n",
    "ISL - http://www-bcf.usc.edu/~gareth/ISL/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Forward Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead of choosing from all $2^p$ models, we start with a model with no predictors, and then add predictors one at a time to see if it helps the model until either all the predictors are added, or there is no additional benefit to adding a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Start with the simple model: $y = \\beta_0$\n",
    "\n",
    "2. for $ j = 0 \\dots, p-1 $:\n",
    "    - Fit all $p - j$ models that add 1 predictor to the current model\n",
    "    - Select the best among these\n",
    "        + This can be done by looking at minimizing RSS, or looking at $R^2$\n",
    "3. Select the best model according to $C_p$, BIC, or adjusted $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Start with the simple model: $y = \\beta_0$\n",
    "\n",
    "2. for $ j = 0 \\dots, p-1 $:\n",
    "    - Fit all $p - j$ models that add 1 predictor to the current model\n",
    "    - Select the best among these\n",
    "        + Run a F-test to check for model significance. Pick the model with the highest $p-value$\n",
    "\n",
    "3. Continue until the F-test is no longer significant at the desired $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# From https://planspace.org/20150423-forward_selection_with_statsmodels/\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def forward_selected(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These methods are greedy -- they consider only a small subset of the possible models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backward Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Exactly the opposite procedure of Forward Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Start with the full model: $ y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 \\dots \\beta_px_p $\n",
    "2. for $j = p, p-1 \\dots 1$:\n",
    "    - Consider all $j$ models that contain every predictor except 1\n",
    "    - Choose the best model out of these\n",
    "3. Select the best model according to $C_p$, BIC, or adjusted $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These two approaches may arrive at different models! Backwards selection tends to select too many variables, while forwards selection selects too few"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Forward-Backward selection (Stepwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This procedure, which was inspired by the forward stepwise selection and backward stepwise selection procedure, works as follows:\n",
    "\n",
    "Define $\\alpha_1$ to be the significance cutoff to add a variable and $\\alpha_2$ to be the significance level for removing a variable.\n",
    "\n",
    "1. Start with the null model: $y = \\beta_0$\n",
    "2. Perform 1 step of the Forward Stepwise Selection Procedure, looking at the the F-test p-value to determine which variable to add.\n",
    "3. After each Forward Stepwise Selection Procedure step, check the significance of each of the other predictors in the model, and remove them if they fall below $\\alpha_2$.\n",
    "4. Continue until all variables are in the model, or Forward Stepwise Selection Procedure falls above $\\alpha_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing a best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Remember that $R^2$, which is a function of RSS, always increases when you add predictors. Therefore, it is not a good measure for which model is best. \n",
    "\n",
    "RSS = Residual Sum of Squares = $\\sum_{i=1}^{m} (y_i - f(\\boldsymbol{x_i}))^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### $C_p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If a model has $d$ predictors, $C_p$ estimates the *test* MSE:\n",
    "\n",
    "$$ C_p = \\frac{1}{n}(RSS + 2d\\hat{\\sigma}^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "where $\\sigma^2$ is an estimate of the variance of the error $\\epsilon_i$. (For linear regression, the full form is $y = \\beta_0 + \\beta_1x_1 \\dots \\beta_dx_d + \\epsilon_i, \\epsilon_i \\sim N(0, \\sigma^2)$ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice how this goes up as the the number of predictors increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayesian Information Criterion (BIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The BIC looks like $C_p$, but is derived from the bayesian point of view.\n",
    "\n",
    "It is given by:\n",
    "\n",
    "$$ BIC = \\frac{1}{n}(RSS + log(n)d\\hat{\\sigma}^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It replaces the factor of 2 in the $C_p$ with log(n). However, for any n > 7, this will end up being >2. Therefore, the BIC is often said to result in smaller models than $C_p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adjusted $R^2$\n",
    "\n",
    "Recall that $R^2 = RSS/TSS$\n",
    "\n",
    "OR\n",
    "\n",
    "$$R^2 = \\frac{var(\\boldsymbol{\\beta}^T\\textbf{x})}{var(y)} = \\frac{\\Sigma_{i=1}^n(\\hat{y}_i - \\bar{y})^2}{\\Sigma_{i=1}^n(y_i - \\bar{y})} $$\n",
    "\n",
    "The Adjusted $R^2$ is a method to use $R^2$ to select models. As we have seen, $R^2$ tends to increase when you add variables to a model. Therfore, adjusted $R^2$ penalizes the number of parameters:\n",
    "\n",
    "$$Adjusted R^2 = 1 - \\frac{RSS/(n-d-1)}{TSS/(n-1)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In linear regression, we try to minimize the mean square error, which in general is given by\n",
    "\n",
    "$$ MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{f}(x_i))^2 $$ where $\\hat{f}(x_i)$ is your model prediction.\n",
    "\n",
    "Let's say the true model for Y is given by $Y = f(x)$\n",
    "\n",
    "We can define a bias as being $E[\\hat{f}(x)] - f(x)$\n",
    "\n",
    "Then, we can decompose the expression as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$ E[(\\hat{f}(x) - f(x))^2] = MSE$$\n",
    "\n",
    "define $\\mu = E[\\hat{f}(x)]$\n",
    "\n",
    "$$ E[(\\hat{f}(x) - f(x))^2] = E[(\\hat{f}(x) - \\mu) + (\\mu - f(x))^2] $$\n",
    "\n",
    "$$ = E[(\\hat{f}(x) - \\mu)^2 + 2(\\hat{f}(x) - \\mu)(\\mu - f(x)) + (\\mu-f(x))^2] $$\n",
    "\n",
    "Note that $E[\\hat{f}(x) - \\mu] = E[\\hat{f}(x) - E[\\hat{f}(x)]] = 0 $\n",
    "\n",
    "$$ E[(\\hat{f}(x) - f(x))^2] = E[(\\hat{f}(x) - E[\\hat{f}(x)])^2] + (E[\\hat{f}(x)] - f(x))^2 $$\n",
    "$$ = var(\\hat{f}(x)) + bias(\\hat{f}(x))^2 $$\n",
    "\n",
    "*note:* Here, we've ommitted another term which is the *irreducible* error from $Var(\\epsilon)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What is $var(\\hat{f}(x))$? What is the bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The *variance* refers to how much $\\hat{f}(x)$ changes if it were estimated from a different training set. Ideally, this variance would be small, since small changes in the dataset should not produce a large change in the model estimate. \n",
    "\n",
    "In general, more flexible methods have higher variance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The *bias* arises because we are often trying to model a complex phenomenon, but the model is too simplistic, or does not have enough information to perfectly model the phenomenon. Does a linear regression actually capture all of the intracacies and nonlinear patterns in the data?\n",
    "\n",
    "Generally, more flexible methods tend to have lower bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In general, as the methods become more flexible (more parameters, etc.), the variance will increase and the bias will decrease. This is where the trade-off comes from. The goal of model selection should be to find the right mix of bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You could draw a line through every point (low bias, high variance) or draw just a horizontal line (high bias, low variance). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](./assets/biasvariance.png)\n",
    "http://www-bcf.usc.edu/~gareth/ISL/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other variables selection methods: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Other methods that can be used *prior* to fitting any models generally involve looking at how related each of the features are with the outcome of interest. For example, you could choose some metric (correlation, mutual information, etc.) and rank all of the features and then select the top *k* or *x%* of the features.\n",
    "\n",
    "[Scitkit learn reference](https://scikit-learn.org/stable/modules/feature_selection.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we could look at our matrix, which has 266 variables, and select the top 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 266)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>ind__Asian</th>\n",
       "      <th>...</th>\n",
       "      <th>ind__Ulcerat col</th>\n",
       "      <th>ind__Unclassified</th>\n",
       "      <th>ind__Urin stone</th>\n",
       "      <th>ind__Uterus cancr</th>\n",
       "      <th>ind__Varicose vn</th>\n",
       "      <th>ind__Viral infect</th>\n",
       "      <th>ind__Wht blood dx</th>\n",
       "      <th>ind__chf;nonhp</th>\n",
       "      <th>ind__gu cong anom</th>\n",
       "      <th>ind__nan_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2278392</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>149190</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>64410</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>500364</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>16680</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0       2278392                  41               0                1   \n",
       "1        149190                  59               0               18   \n",
       "2         64410                  11               5               13   \n",
       "3        500364                  44               1               16   \n",
       "4         16680                  51               0                8   \n",
       "\n",
       "   number_outpatient  number_emergency  number_inpatient  number_diagnoses  \\\n",
       "0                  0                 0                 0                 1   \n",
       "1                  0                 0                 0                 9   \n",
       "2                  2                 0                 1                 6   \n",
       "3                  0                 0                 0                 7   \n",
       "4                  0                 0                 0                 5   \n",
       "\n",
       "   time_in_hospital  ind__Asian  ...  ind__Ulcerat col  ind__Unclassified  \\\n",
       "0                 1           0  ...                 0                  0   \n",
       "1                 3           0  ...                 0                  0   \n",
       "2                 2           0  ...                 0                  0   \n",
       "3                 2           0  ...                 0                  0   \n",
       "4                 1           0  ...                 0                  0   \n",
       "\n",
       "   ind__Urin stone  ind__Uterus cancr  ind__Varicose vn  ind__Viral infect  \\\n",
       "0                0                  0                 0                  0   \n",
       "1                0                  0                 0                  0   \n",
       "2                0                  0                 0                  0   \n",
       "3                0                  0                 0                  0   \n",
       "4                0                  0                 0                  0   \n",
       "\n",
       "   ind__Wht blood dx  ind__chf;nonhp  ind__gu cong anom  ind__nan_y  \n",
       "0                  0               0                  0           2  \n",
       "1                  0               0                  0           0  \n",
       "2                  0               0                  0           2  \n",
       "3                  0               0                  0           0  \n",
       "4                  0               0                  0           1  \n",
       "\n",
       "[5 rows x 266 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the object\n",
    "selector = SelectKBest(mutual_info_classif, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=50, score_func=<function mutual_info_classif at 0xa20958d40>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.fit(X=model_dataset.iloc[:, 2:], y=model_dataset.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.65203387e-02, 4.50796479e-02, 9.79541668e-03, 0.00000000e+00,\n",
       "       3.95922976e-03, 2.49536205e-02, 6.73975440e-02, 1.84576769e-03,\n",
       "       5.97348107e-03, 0.00000000e+00, 6.09655091e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.89419422e-03, 6.38848470e-03, 2.62574806e-02,\n",
       "       0.00000000e+00, 4.08005845e-02, 1.11957573e-02, 1.39189889e-03,\n",
       "       1.80932427e-03, 1.38836470e-03, 1.57159179e-03, 5.56767675e-03,\n",
       "       7.32163538e-04, 1.00246477e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.11667256e-04, 2.95424998e-03, 5.69640462e-03, 5.89616849e-03,\n",
       "       6.68179474e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.75013711e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 8.80164792e-04, 0.00000000e+00, 9.26600912e-04,\n",
       "       2.06453426e-03, 0.00000000e+00, 0.00000000e+00, 2.40303979e-04,\n",
       "       4.40237361e-03, 0.00000000e+00, 4.39732772e-04, 1.83095728e-03,\n",
       "       7.81963554e-04, 4.64377420e-02, 3.45312042e-03, 1.61844221e-03,\n",
       "       3.72019962e-04, 4.62973483e-04, 1.22300761e-03, 4.19479805e-03,\n",
       "       5.38651225e-02, 2.79501710e-03, 7.30062467e-03, 5.61370276e-05,\n",
       "       0.00000000e+00, 4.89746278e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.63700683e-05, 4.97865610e-03, 3.83170849e-03, 6.23533061e-04,\n",
       "       0.00000000e+00, 1.34348486e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.01752779e-03, 2.60482307e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.07883271e-03, 2.65689232e-03, 1.85436265e-03, 4.66800334e-03,\n",
       "       0.00000000e+00, 1.77188012e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.43229512e-03, 1.46426960e-03, 0.00000000e+00, 4.78166926e-03,\n",
       "       0.00000000e+00, 6.73964560e-03, 0.00000000e+00, 4.09088209e-03,\n",
       "       0.00000000e+00, 1.75167660e-03, 5.45091382e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 7.96022408e-04, 3.51845182e-03, 7.59766319e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.78091463e-03, 2.30141546e-03,\n",
       "       0.00000000e+00, 2.01029383e-03, 5.16753931e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.14653095e-03, 0.00000000e+00, 1.67531485e-03,\n",
       "       2.94094294e-03, 0.00000000e+00, 0.00000000e+00, 2.35206773e-03,\n",
       "       3.21030876e-03, 0.00000000e+00, 4.44564202e-03, 6.77030750e-03,\n",
       "       0.00000000e+00, 6.03435053e-03, 1.19999973e-03, 1.45669827e-03,\n",
       "       9.58671202e-04, 1.54708636e-03, 0.00000000e+00, 6.20404773e-04,\n",
       "       0.00000000e+00, 1.76534650e-04, 0.00000000e+00, 2.68433784e-03,\n",
       "       0.00000000e+00, 1.13842111e-03, 3.37036505e-03, 2.73831532e-03,\n",
       "       3.85867549e-04, 5.30850911e-03, 0.00000000e+00, 7.47099171e-04,\n",
       "       6.26784781e-04, 1.09744240e-03, 6.90189472e-03, 3.09955419e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.83602540e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.14269260e-03,\n",
       "       1.84808430e-03, 0.00000000e+00, 3.04267324e-03, 2.82456675e-03,\n",
       "       3.55302671e-04, 1.21221166e-03, 0.00000000e+00, 7.02421196e-04,\n",
       "       0.00000000e+00, 2.94020543e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.46214024e-03, 8.68720029e-04, 6.54350815e-04, 1.24431522e-03,\n",
       "       3.16792528e-03, 5.46112946e-04, 0.00000000e+00, 6.93848473e-04,\n",
       "       7.69711395e-04, 3.45689158e-04, 4.81369398e-05, 7.61522711e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.14470313e-03, 2.82977233e-04,\n",
       "       0.00000000e+00, 4.85789015e-03, 1.32428309e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 5.16892722e-03, 3.48747194e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 4.43565299e-04, 4.67064225e-03, 4.17433392e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.22010017e-03, 0.00000000e+00,\n",
       "       9.93710075e-04, 0.00000000e+00, 1.48952929e-03, 1.17664153e-03,\n",
       "       3.26781585e-03, 1.58160325e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       5.59764020e-04, 3.79565103e-03, 0.00000000e+00, 2.16007353e-03,\n",
       "       1.43422662e-03, 3.74304148e-03, 1.37425992e-04, 1.88733624e-03,\n",
       "       0.00000000e+00, 4.02547342e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       7.78013205e-04, 2.38184649e-03, 3.51216581e-03, 2.33904372e-03,\n",
       "       0.00000000e+00, 1.00220842e-03, 3.34279710e-03, 6.83429920e-03,\n",
       "       3.44508868e-03, 2.67301465e-03, 1.71889342e-03, 4.76947581e-03,\n",
       "       0.00000000e+00, 1.48246326e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       4.12385766e-03, 9.47705863e-04, 2.71052486e-03, 3.69531824e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.16184858e-03,\n",
       "       0.00000000e+00, 1.18342829e-03, 4.51607952e-04, 2.12355237e-03,\n",
       "       1.30307634e-03, 1.82255178e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       5.48433993e-03, 0.00000000e+00, 2.94065579e-03, 8.07998732e-04,\n",
       "       8.97990541e-04, 0.00000000e+00, 0.00000000e+00, 1.06790384e-03,\n",
       "       0.00000000e+00, 4.89873051e-03, 1.13283825e-03, 0.00000000e+00])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6,  60,  53,   1,  17,  15,   5,   0,  18,   2,  62, 146, 227,\n",
       "       106, 123,  93,  32,  14, 125,   8,  31,  30,  23, 252,  98, 141,\n",
       "       189, 110,  69, 261,  65, 185,  91, 231, 194,  83, 122,  48,  59,\n",
       "       195, 236,  95, 217,   4,  70, 209, 213, 102, 222, 190,  54, 228,\n",
       "       138, 226, 204, 120, 172, 147,  80, 158,  29, 116, 254, 165, 159,\n",
       "        61,  38, 139, 238, 135, 229,  81,  77, 221, 119, 223, 107, 198,\n",
       "       211, 182, 247,  44,  76, 109,  13, 215,  82, 156,   7, 150,  51,\n",
       "       249,  20,  97, 230, 115,  55, 205,  22, 129, 202, 233,  89, 168,\n",
       "       127, 212,  88,  19,  21,  73, 186, 248, 171,  58, 161, 126, 245,\n",
       "       203, 243, 113, 155, 137, 262, 145, 259,  25, 225, 200, 128, 237,\n",
       "        43, 256,  41, 169, 255, 101,  52, 220, 176, 179, 103, 143,  24,\n",
       "       163, 175, 170, 144,  71, 131,  10, 208, 173,  57, 246, 193,  50,\n",
       "       140,  56, 160, 177, 183,  47,  85, 133, 214,  28,  63, 178, 239,\n",
       "        68, 206, 260,  37,  36,  39, 251,  40, 201,  42,  34, 199, 197,\n",
       "        45,  46, 196,  49,  35, 210,  33, 207, 253,   9, 257,  11,  12,\n",
       "       244, 242, 241,  16, 240, 235, 234, 232, 224, 219, 218, 216,  26,\n",
       "         3, 250, 258,  27, 114, 192, 100, 151,  90, 149,  92, 148,  94,\n",
       "       142,  96, 136,  99, 134,  87, 132, 104, 105, 130, 124, 108, 121,\n",
       "       118, 111, 112, 152,  86, 191, 167, 188, 187, 117, 184, 181, 180,\n",
       "        64,  66,  67, 174,  72,  84, 166,  74,  75, 164, 162,  78,  79,\n",
       "       157, 154, 153, 263])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(selector.scores_)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_in_hospital',\n",
       " 'admission_source_id_17.0',\n",
       " 'admission_source_id_7.0',\n",
       " 'num_medications',\n",
       " 'admission_type_id_5.0',\n",
       " 'admission_type_id_3.0',\n",
       " 'number_diagnoses',\n",
       " 'num_procedures',\n",
       " 'admission_type_id_6.0',\n",
       " 'number_outpatient',\n",
       " 'admission_source_id_22.0',\n",
       " 'ind__Int obstruct',\n",
       " 'ind__Precere occl',\n",
       " 'ind__DiabMel w/cm',\n",
       " 'ind__Exam/eval',\n",
       " 'ind__Cervix cancr',\n",
       " 'discharge_disposition_id_12.0',\n",
       " 'admission_type_id_2.0',\n",
       " 'ind__Fluid/elc dx',\n",
       " 'ind__Caucasian',\n",
       " 'discharge_disposition_id_11.0',\n",
       " 'discharge_disposition_id_10.0',\n",
       " 'discharge_disposition_id_3.0',\n",
       " 'ind__UTI',\n",
       " 'ind__Complic proc',\n",
       " 'ind__Htn complicn',\n",
       " 'ind__Ot nutrit dx',\n",
       " 'ind__E Codes: Fire/burn',\n",
       " 'ind__Adjustment disorders',\n",
       " 'ind__chf;nonhp',\n",
       " 'ind__Abdomnl pain',\n",
       " 'ind__Ot hematl dx',\n",
       " 'ind__Cardiac anom',\n",
       " 'ind__Rehab',\n",
       " 'ind__Oth CNS infx',\n",
       " 'ind__Bnign ut neo',\n",
       " 'ind__Esophgeal dx',\n",
       " 'admission_source_id_2.0',\n",
       " 'admission_source_id_14.0',\n",
       " 'ind__Oth bact inf',\n",
       " 'ind__Septicemia',\n",
       " 'ind__Coag/hemr dx',\n",
       " 'ind__Parkinson-s',\n",
       " 'number_inpatient',\n",
       " 'ind__Alcohol-related disorders',\n",
       " 'ind__Other pregnancy and delivery including normal',\n",
       " 'ind__PID',\n",
       " 'ind__Crush injury',\n",
       " 'ind__Pleurisy',\n",
       " 'ind__Ot primry ca']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(model_dataset.iloc[:, 2:].columns)[x] for x in np.argsort(selector.scores_)[::-1][0:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0, ...,  0,  0,  0],\n",
       "       [ 0, 18,  0, ...,  0,  0,  0],\n",
       "       [ 5, 13,  2, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  9,  1, ...,  1,  0,  0],\n",
       "       [ 2, 21,  0, ...,  0,  0,  0],\n",
       "       [ 3,  3,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.transform(model_dataset.iloc[:, 2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Shrinkage methods and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Rather than explicitly selecting variables, we can *constrain* or *regularize* the coefficient estimates. These are known as *shrinkage* methods because they *shrink* the coefficient estimates towards 0. The reason why this might be a good idea is that it can often dramatically reduce the variance in the estimates, which we will discuss later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The two most popular methods for regularization are known as Ridge Regression and LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Remember that in linear regression, we are interested in minimizing the squared-error loss, or maximizing the log likelihood. \n",
    "\n",
    "$$ \\hat{\\beta} = \\underset{\\beta}{\\arg\\min} \\sum_{i=1}^{n}(y_i - \\boldsymbol{\\beta}^T\\boldsymbol{x_i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In Ridge Regression, we add a penalty so that sum of squared $\\beta$ terms does not get too large. \n",
    "\n",
    "$$ \\hat{\\beta} = \\underset{\\beta}{\\arg\\min} \\sum_{i=1}^{n}(y_i - \\beta_0 - \\sum_{j=1}^{p}x_{ij}\\beta_j)^2 + \\lambda\\sum_{j=1}^{p}\\beta_j^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Where $\\lambda$ controls the amount of shrinkage. Higher values of $\\lambda$ will result in more shrinkage. This applies for more than just the linear regression problem, and is known *weight decay* in neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Often, we want to standardize the inputs before running regularization so that the penalty is applied evenly. We can standardize a given variable x, by\n",
    "\n",
    "$$ z_i = \\frac{x_i - \\bar{x}}{\\sigma(x)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "in addition, we only want to penalize the non-intercept terms. If all of the predictors have been standardized, then $\\beta_0$ is just the mean of the y values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The LASSO penalty is similar to the ridge penalty:\n",
    "\n",
    "$$ \\hat{\\beta} = \\underset{\\beta}{\\arg\\min} \\sum_{i=1}^{n}(y_i - \\beta_0 - \\sum_{j=1}^{p}x_{ij}\\beta_j)^2 + \\lambda\\sum_{j=1}^{p}|\\beta_j|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Again, the same $\\lambda$ parameter controls the regularization. Unlike the ridge regression, this can actually shrink some of the coefficients, $\\beta$ to 0. Therefore, unlike Ridge Regression, the LASSO also preforms *variable selection*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](./assets/full.png)\n",
    "https://www.linkedin.com/pulse/intuitive-visual-explanation-differences-between-l1-l2-xiaoli-chen/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constraint (penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](./assets/constraint.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MSE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](./assets/elipses.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Increasing Penalty "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](./assets/increase_penalty.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are other methods that take both the ridge approach as well as the LASSO approach. One such method is known as the Elastic Net.\n",
    "\n",
    "$$ \\hat{\\beta} = \\underset{\\beta}{\\arg\\min} \\sum_{i=1}^{n}(y_i - \\beta_0 - \\sum_{j=1}^{p}x_{ij}\\beta_j)^2 + \\lambda_1\\sum_{j=1}^{p}|\\beta_j| + \\lambda_2\\sum_{j=1}^{p}\\beta_j^2$$\n",
    "\n",
    "This is often used for problems known as \"large $p$, small $n$\", where the number of predictors is quite large in comparison to the number of samples, which is common in genomics. Ridge Regression may not be able to run due to the large number of predictors, but the LASSO may select too few parameters (it will shrink too many to 0).\n",
    "\n",
    "This is a good middle ground that will select groups of correlated predictors, in theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso in action: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> class sklearn.linear_model.Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the object: \n",
    "lr = Lasso(alpha=.001, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=True, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X=model_dataset.iloc[:, 2:],\n",
    "       y=model_dataset.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admission_type_id_6.0',\n",
       " 'admission_source_id_6.0',\n",
       " 'admission_source_id_7.0',\n",
       " 'discharge_disposition_id_11.0',\n",
       " 'ind__DiabMel w/cm',\n",
       " 'ind__UTI',\n",
       " 'ind__Septicemia',\n",
       " 'ind__Fluid/elc dx',\n",
       " 'admission_source_id_9.0',\n",
       " 'ind__Alcohol-related disorders',\n",
       " 'ind__Pancreas dx',\n",
       " 'ind__Abdomnl pain',\n",
       " 'ind__Hrt valve dx',\n",
       " 'time_in_hospital',\n",
       " 'ind__Wht blood dx',\n",
       " 'ind__Pleurisy',\n",
       " 'ind__Coag/hemr dx',\n",
       " 'num_medications',\n",
       " 'ind__Oth liver dx',\n",
       " 'number_diagnoses',\n",
       " 'ind__chf;nonhp',\n",
       " 'ind__Acute MI',\n",
       " 'ind__Bone/ct cncr',\n",
       " 'ind__Brain/ns can',\n",
       " 'ind__Coma/brn dmg',\n",
       " 'ind__Colon cancer',\n",
       " 'ind__Biliary dx',\n",
       " 'ind__Chr kidney disease',\n",
       " 'ind__Art embolism',\n",
       " 'ind__Cervix cancr',\n",
       " 'ind__Carditis',\n",
       " 'ind__Cardiac anom',\n",
       " 'ind__Bladder cncr',\n",
       " 'ind__COPD',\n",
       " 'ind__Anxiety disorders',\n",
       " 'ind__Asp pneumon',\n",
       " 'ind__Burns',\n",
       " 'ind__Contraceptiv',\n",
       " 'ind__Appendicitis',\n",
       " 'ind__Bronchitis',\n",
       " 'ind__Breast dx']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(model_dataset.iloc[:, 2:].columns)[x] for x in np.argsort(lr.coef_)[::-1][0:41]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_in_hospital',\n",
       " 'admission_source_id_17.0',\n",
       " 'admission_source_id_7.0',\n",
       " 'num_medications',\n",
       " 'admission_type_id_5.0',\n",
       " 'admission_type_id_3.0',\n",
       " 'number_diagnoses',\n",
       " 'num_procedures',\n",
       " 'admission_type_id_6.0',\n",
       " 'number_outpatient',\n",
       " 'admission_source_id_22.0',\n",
       " 'ind__Int obstruct',\n",
       " 'ind__Precere occl',\n",
       " 'ind__DiabMel w/cm',\n",
       " 'ind__Exam/eval',\n",
       " 'ind__Cervix cancr',\n",
       " 'discharge_disposition_id_12.0',\n",
       " 'admission_type_id_2.0',\n",
       " 'ind__Fluid/elc dx',\n",
       " 'ind__Caucasian',\n",
       " 'discharge_disposition_id_11.0',\n",
       " 'discharge_disposition_id_10.0',\n",
       " 'discharge_disposition_id_3.0',\n",
       " 'ind__UTI',\n",
       " 'ind__Complic proc',\n",
       " 'ind__Htn complicn',\n",
       " 'ind__Ot nutrit dx',\n",
       " 'ind__E Codes: Fire/burn',\n",
       " 'ind__Adjustment disorders',\n",
       " 'ind__chf;nonhp',\n",
       " 'ind__Abdomnl pain',\n",
       " 'ind__Ot hematl dx',\n",
       " 'ind__Cardiac anom',\n",
       " 'ind__Rehab',\n",
       " 'ind__Oth CNS infx',\n",
       " 'ind__Bnign ut neo',\n",
       " 'ind__Esophgeal dx',\n",
       " 'admission_source_id_2.0',\n",
       " 'admission_source_id_14.0',\n",
       " 'ind__Oth bact inf',\n",
       " 'ind__Septicemia',\n",
       " 'ind__Coag/hemr dx',\n",
       " 'ind__Parkinson-s',\n",
       " 'number_inpatient',\n",
       " 'ind__Alcohol-related disorders',\n",
       " 'ind__Other pregnancy and delivery including normal',\n",
       " 'ind__PID',\n",
       " 'ind__Crush injury',\n",
       " 'ind__Pleurisy',\n",
       " 'ind__Ot primry ca']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(model_dataset.iloc[:, 2:].columns)[x] for x in np.argsort(selector.scores_)[::-1][0:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['admission_source_id_7.0', 'admission_type_id_6.0',\n",
       "       'discharge_disposition_id_11.0', 'ind__Abdomnl pain',\n",
       "       'ind__Alcohol-related disorders', 'ind__Cardiac anom',\n",
       "       'ind__Cervix cancr', 'ind__Coag/hemr dx', 'ind__DiabMel w/cm',\n",
       "       'ind__Fluid/elc dx', 'ind__Pleurisy', 'ind__Septicemia',\n",
       "       'ind__UTI', 'ind__chf;nonhp', 'num_medications',\n",
       "       'number_diagnoses', 'time_in_hospital'], dtype='<U50')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d([list(model_dataset.iloc[:, 2:].columns)[x] for x in np.argsort(lr.coef_)[::-1][0:41]], [list(model_dataset.iloc[:, 2:].columns)[x] for x in np.argsort(selector.scores_)[::-1][0:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge doesn't select "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver='auto', random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(alpha=10, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None, normalize=True,\n",
       "      random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg.fit(X=model_dataset.iloc[:, 2:],\n",
    "       y=model_dataset.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.63141555e-02,  5.57795899e-02, -1.06345410e-02, -9.85371200e-03,\n",
       "        4.19108084e-02,  1.20198868e-01,  1.78330056e-01, -1.63561261e-01,\n",
       "       -9.02865313e-02, -1.62663655e-02,  2.82350828e-02,  1.10341920e-01,\n",
       "       -4.48945520e-03, -7.40645651e-01, -2.45934158e-01, -8.50890319e-01,\n",
       "        3.45694555e-01, -1.47567534e+00,  9.25172976e-01,  3.53737523e-01,\n",
       "        1.77048200e-01,  0.00000000e+00,  1.19028012e-01,  2.02286478e-01,\n",
       "       -1.29325954e-01,  3.06342153e-01,  6.50002532e-02,  1.87483249e-01,\n",
       "        1.72275517e-01,  2.51683006e-04,  9.22448441e-01,  7.74883598e-01,\n",
       "       -4.69846619e-01,  3.40267457e-01,  3.64956200e-01,  1.41041267e-01,\n",
       "       -2.07732440e+00, -2.10051542e+00,  1.67666335e-03, -9.15946557e-02,\n",
       "       -7.44698531e-01, -9.27818252e-02,  1.53752283e-01, -1.76740830e-01,\n",
       "       -4.14179079e-01,  3.50081458e-01,  3.14408491e-01,  0.00000000e+00,\n",
       "       -1.28779517e-01, -1.90840564e-01, -3.58385458e-01,  3.31973463e-01,\n",
       "        7.30968826e-01,  8.02841455e-01, -2.84077488e-01,  5.20055109e-01,\n",
       "        3.93756954e-02, -3.26058551e+00, -3.71829523e+00,  2.12961159e+00,\n",
       "       -9.48448859e-01,  1.90960022e-01, -1.09843871e+00,  9.56989120e-01,\n",
       "        0.00000000e+00,  3.67966825e-01, -1.66588598e+00,  2.22688275e-01,\n",
       "        4.25814874e-01, -4.13221692e-01,  3.94249234e-01,  1.26127299e-01,\n",
       "       -2.28581862e-02, -5.04780593e-02, -1.26949059e-01, -2.75194025e-01,\n",
       "        2.66691885e-01, -3.19169609e-01,  4.57384260e-01, -1.11343670e+00,\n",
       "       -6.63816371e-01,  4.10395337e-01, -3.19064598e-01, -8.14777426e-01,\n",
       "       -4.87382685e-01, -2.03869266e-01, -1.20848515e+00, -6.94075873e-01,\n",
       "        1.83505373e-01, -2.02023329e+00,  1.54087231e-01,  3.26905077e-01,\n",
       "        8.21076828e-02,  8.78540595e-01,  2.57674935e-01,  3.73456927e-01,\n",
       "       -7.10374380e-02,  3.92786166e-02, -1.69819391e-01, -4.16245776e-01,\n",
       "       -1.53475346e+00, -1.35245761e-01,  1.94990460e-01, -5.52401665e-02,\n",
       "        6.32298342e-02, -1.96356413e-01,  4.45677885e-01, -8.19549006e-03,\n",
       "       -1.70922410e+00, -1.09713338e-01, -6.16193341e-01,  2.89978584e+00,\n",
       "       -3.09903498e-01, -6.25903868e-01, -1.11993371e+00, -3.00683904e+00,\n",
       "        1.34230754e-02,  1.97313831e-01,  9.70033449e-01, -1.42869226e+00,\n",
       "        5.58442678e-02, -3.81570035e-02, -2.40356379e-01, -1.71600520e+00,\n",
       "       -3.75577807e-02,  3.47825443e-01, -3.06530407e-01, -3.86091332e-01,\n",
       "       -4.92006189e-01, -2.75523641e-02,  2.11384720e-01,  1.81280402e-01,\n",
       "        1.93482100e-01, -3.60230999e+00,  4.68551170e-02,  4.16757091e-01,\n",
       "       -5.50058717e-01, -1.97993064e-01, -2.33912161e-01,  1.04048466e-01,\n",
       "        2.91666111e-01, -2.44044126e-01, -3.98275268e-01, -4.79379977e-01,\n",
       "       -4.90063936e-02, -3.79553437e-01,  2.18780968e-01,  2.78028766e-01,\n",
       "       -3.61232036e-01, -3.84165612e-01, -3.79117751e-01, -2.01677123e-01,\n",
       "        2.76211421e-01,  3.02385635e-01, -1.60803473e-01, -5.07059843e-01,\n",
       "       -2.93243986e-01,  1.63872101e-01, -1.16182850e+00, -1.06416675e+00,\n",
       "        3.53338820e-01,  1.93498241e-02,  2.62944010e-01,  4.03834394e-01,\n",
       "       -5.60615454e-02,  3.36543991e-01,  5.20815595e-01, -1.33110686e+00,\n",
       "       -1.24407746e+00,  3.41039928e-01, -5.28787580e-01, -3.30397347e-01,\n",
       "       -9.40915358e-01, -8.68175268e-01, -3.41383024e-01, -5.04370679e-01,\n",
       "       -1.76504264e-01, -7.76718977e-01, -6.81646426e-01, -1.02963801e-01,\n",
       "       -1.68186322e-01,  1.09774493e-02,  1.77551279e-03, -3.53186419e-02,\n",
       "       -1.22528737e+00,  2.61371750e-01,  2.96281152e-02,  7.80737236e-03,\n",
       "       -1.39321037e-01, -7.68304852e-01, -1.46646139e+00,  1.66622810e-01,\n",
       "       -1.21707790e-01, -5.05410215e-01,  9.44503945e-01,  1.14938696e-01,\n",
       "       -4.82778965e-01, -4.27417984e-01,  4.98444374e-01,  3.98736132e-01,\n",
       "       -1.28364396e+00, -9.16986649e-03, -6.00759546e-01, -4.25722178e-01,\n",
       "        2.20809843e-01, -1.28040930e-01,  6.43659103e-01, -7.93452135e-01,\n",
       "        1.67467759e-01, -1.48282533e+00, -1.63126828e+00, -5.98813441e-01,\n",
       "        1.77164372e-01, -5.34258271e-01,  1.53003741e-01,  4.99229451e-01,\n",
       "       -3.24847968e-02, -7.98188372e-03, -2.88825117e-01,  3.59603004e-01,\n",
       "       -4.54018046e-01, -4.99017452e-02,  5.22528089e-01,  5.59698599e-01,\n",
       "        3.30980470e-01,  9.55664101e-02,  7.41074657e-01, -5.14171736e-01,\n",
       "       -1.04243138e+00,  1.88169512e-01, -2.63896687e-01, -6.65277953e-01,\n",
       "       -2.72131012e-01,  1.59761000e-01, -3.41056240e-01,  9.26189441e-01,\n",
       "        8.59705140e-01,  1.20786886e-01, -5.42343846e-02, -4.10708988e-01,\n",
       "       -6.90137595e-02, -9.77040719e-01,  1.14392442e-01,  1.55584794e-01,\n",
       "        1.39774290e+00, -2.92459269e-01, -1.26494955e-02, -4.51221465e-02,\n",
       "        2.03538337e-01, -3.21822306e-01, -1.62537683e+00, -2.19697618e-01,\n",
       "        5.15818439e-01,  3.61012725e-04,  2.81944764e-01, -1.71313975e-01,\n",
       "       -1.46388309e-01, -1.10212099e+00,  2.33437312e-02,  3.76564620e-01,\n",
       "        6.79841857e-01,  2.34225919e-01, -2.62512072e-01, -1.61628335e-01])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg.coef_"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
